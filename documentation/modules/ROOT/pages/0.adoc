= ¡Bienvenido al taller!
include::_attributes.adoc[]

El mundo de la inteligencia artificial generativa avanza cada día y adaptarse a su ritmo es un reto recurrente para las empresas. En Red Hat, proponemos Red Hat AI. Se trata de una plataforma especializada en la gestión del ciclo de vida de las aplicaciones basadas en IA predictiva y generativa. De esta forma, centralizamos todas las herramientas necesarias para acelerar el desarrollo y despliegue de apps de IA.

En este caso, nos adentraremos en uno de los últimos avances de la IA generativa, los agentes. ¿Qué diferencia hay entre los modelos con los que interactuamos mediante chat y estos agentes?

Los modelos conversacionales son algoritmos de predicción de lenguaje. Se encargan de recibir y procesar información para después dar una respuesta. Estos modelos requieren de entrenamiento para aprender a predecir qué decir según lo recibido. Los modelos propietarios (OpenAI ChatGPT, Google Gemini...) son gigantescos. Requieren de una potencia computacional muy grande para ser entrenados y al ser privados, no pueden ser reentrenados y requieren acceso continuo a internet.

La buena noticia es que los modelos conversacionales open-source (Meta Llama 4, Mistral Large 3...) han ido ganando terreno. En base a los últimos benchmarks, estos modelos consiguen resultados casi tan buenos como los modelos propietarios. La ventaja de los modelos open-source es que son mucho más pequeños permitiéndonos reentrenarlos y ejecutarlos en nuestra propia infraestructura.

Un modelo sólo responde en base a lo que conoce. Es ahí donde entran los agentes. En un agente, proporcionamos a los modelos herramientas para mejorar sus respuestas. Mecanismos como RAG (Retrieval-Augmented Generation), búsqueda de información en la web o interacción con servidores MCP (Model Context Protocol).

[#01]
== Objetivo


[#02]
== Material

[#03]
== Entorno